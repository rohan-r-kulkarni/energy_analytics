{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb109ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad5b22",
   "metadata": {},
   "source": [
    "import California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e8f33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-contra costa.csv\")\n",
    "cali_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-el dorado.csv\")\n",
    "cali_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-imperial.csv\")\n",
    "cali_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-mariposa.csv\")\n",
    "cali_5=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-placer.csv\")\n",
    "cali_6=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-san diego.csv\")\n",
    "cali_7=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/cali-san fran.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50996e",
   "metadata": {},
   "source": [
    "import Florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587e1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/fl-bay.csv\")\n",
    "fl_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/fl-broward.csv\")\n",
    "fl_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/fl-duval.csv\")\n",
    "fl_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/fl-leon.csv\")\n",
    "fl_5=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/fl-miami-dade.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb024d",
   "metadata": {},
   "source": [
    "import North Dakota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2caf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/nd-billings.csv\")\n",
    "nd_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/nd-cass.csv\")\n",
    "nd_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/nd-mercer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbde2dc",
   "metadata": {},
   "source": [
    "import New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c9c63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ny-bronx.csv\")\n",
    "ny_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ny-chautauqua.csv\")\n",
    "ny_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ny-queens.csv\")\n",
    "ny_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ny-suffolk.csv\")\n",
    "ny_5=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ny-westchester.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6fc98",
   "metadata": {},
   "source": [
    "import Ohio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97a820c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/oh-butler.csv\")\n",
    "oh_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/oh-cuyahoga.csv\")\n",
    "oh_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/oh-franklin.csv\")\n",
    "oh_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/oh-hamilton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03107571",
   "metadata": {},
   "source": [
    "import Oklahoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3717a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ok-cleveland.csv\")\n",
    "ok_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ok-comanche.csv\")\n",
    "ok_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/ok-pittsburg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1fc5f",
   "metadata": {},
   "source": [
    "import Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658e0d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-centre.csv\")\n",
    "penn_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-dauphin.csv\")\n",
    "penn_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-northampton.csv\")\n",
    "penn_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-philadelphia.csv\")\n",
    "penn_5=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-washington.csv\")\n",
    "penn_6=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/penn-york.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59373ea3",
   "metadata": {},
   "source": [
    "import Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ef4dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-brazoria.csv\")\n",
    "tx_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-cameron.csv\")\n",
    "tx_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-dallas.csv\")\n",
    "tx_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-galveston.csv\")\n",
    "tx_5=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-nueces.csv\")\n",
    "tx_6=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/tx-travis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230e43c",
   "metadata": {},
   "source": [
    "import West Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5c401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wv-brooke.csv\")\n",
    "wv_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wv-marshall.csv\")\n",
    "wv_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wv-tucker.csv\")\n",
    "wv_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wv-wood.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee5ade",
   "metadata": {},
   "source": [
    "import Wyoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "897d4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wy_1=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wy-albany.csv\")\n",
    "wy_2=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wy-lincoln.csv\")\n",
    "wy_3=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wy-sublette.csv\")\n",
    "wy_4=pd.read_csv(\"D:/3.2/Business Analytics/air/all years/wy-teton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c304735",
   "metadata": {},
   "source": [
    "merge by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2dabf56a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cali=cali_1.iloc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b63c785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cali=pd.merge(cali_1,cali_2,how=\"outer\",on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b3aeb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali=cali.iloc[:,[0,1,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ea635c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali=pd.merge(cali,cali_3,how=\"outer\",on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4f22232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali=cali.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ff222a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\562702319.py:1: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  cali4=pd.merge(cali,cali_4,how=\"outer\",on=\"Date\")\n"
     ]
    }
   ],
   "source": [
    "cali4=pd.merge(cali,cali_4,how=\"outer\",on=\"Date\")\n",
    "cali4=cali4.iloc[:,[0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "07cbe47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\3965609205.py:3: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  cali6=pd.merge(cali5,cali_6,how=\"outer\",on=\"Date\")\n"
     ]
    }
   ],
   "source": [
    "cali5=pd.merge(cali4,cali_5,how=\"outer\",on=\"Date\")\n",
    "cali5=cali5.iloc[:,[0,1,2,3,4,5]]\n",
    "cali6=pd.merge(cali5,cali_6,how=\"outer\",on=\"Date\")\n",
    "cali6=cali6.iloc[:,[0,1,2,3,4,5,6]]\n",
    "california=pd.merge(cali6,cali_7,how=\"outer\",on=\"Date\")\n",
    "california=california.iloc[:,[0,1,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b0a432ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "california.columns=['Date','ca1','ca2','ca3','ca4','ca5','ca6','ca7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a3040492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ca1</th>\n",
       "      <th>ca2</th>\n",
       "      <th>ca3</th>\n",
       "      <th>ca4</th>\n",
       "      <th>ca5</th>\n",
       "      <th>ca6</th>\n",
       "      <th>ca7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>158</td>\n",
       "      <td>91.0</td>\n",
       "      <td>105</td>\n",
       "      <td>51.0</td>\n",
       "      <td>122</td>\n",
       "      <td>153</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>66</td>\n",
       "      <td>42.0</td>\n",
       "      <td>49</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>108</td>\n",
       "      <td>89.0</td>\n",
       "      <td>42</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46</td>\n",
       "      <td>98</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>111</td>\n",
       "      <td>51.0</td>\n",
       "      <td>62</td>\n",
       "      <td>38.0</td>\n",
       "      <td>63</td>\n",
       "      <td>111</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>108</td>\n",
       "      <td>40.0</td>\n",
       "      <td>62</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40</td>\n",
       "      <td>111</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>52</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>45</td>\n",
       "      <td>24.0</td>\n",
       "      <td>44</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>31</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>33</td>\n",
       "      <td>29.0</td>\n",
       "      <td>65</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>12/31/2022</td>\n",
       "      <td>36</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42</td>\n",
       "      <td>69</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  ca1   ca2  ca3   ca4  ca5  ca6    ca7\n",
       "0     01/01/2001  158  91.0  105  51.0  122  153  153.0\n",
       "1     01/02/2001   66  42.0   49  38.0   42   96  140.0\n",
       "2     01/03/2001  108  89.0   42  39.0   46   98  140.0\n",
       "3     01/04/2001  111  51.0   62  38.0   63  111  107.0\n",
       "4     01/05/2001  108  40.0   62  38.0   40  111  124.0\n",
       "...          ...  ...   ...  ...   ...  ...  ...    ...\n",
       "8030  12/27/2022   52  32.0  107  37.0   39   54   27.0\n",
       "8031  12/28/2022   45  24.0   44  38.0   39   37   38.0\n",
       "8032  12/29/2022   31  29.0   54  39.0   38   43   25.0\n",
       "8033  12/30/2022   33  29.0   65  31.0   32   53   19.0\n",
       "8034  12/31/2022   36  36.0   60  31.0   42   69   32.0\n",
       "\n",
       "[8035 rows x 8 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc4f62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\3618522138.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  fl4=pd.merge(fl3,fl_4,how=\"outer\",on=\"Date\")\n"
     ]
    }
   ],
   "source": [
    "fl1=fl_1.iloc[:,[0,1]]\n",
    "fl2=pd.merge(fl1,fl_2,how=\"outer\",on=\"Date\")\n",
    "fl2=fl2.iloc[:,[0,1,2]]\n",
    "fl3=pd.merge(fl2,fl_3,how=\"outer\",on=\"Date\")\n",
    "fl3=fl3.iloc[:,[0,1,2,3]]\n",
    "fl4=pd.merge(fl3,fl_4,how=\"outer\",on=\"Date\")\n",
    "fl4=fl4.iloc[:,[0,1,2,3,4]]\n",
    "florida=pd.merge(fl4,fl_5,how=\"outer\",on=\"Date\")\n",
    "florida=florida.iloc[:,[0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e85b7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "florida.columns=['Date','fl1','fl2','fl3','fl4','fl5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ed41a2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>fl1</th>\n",
       "      <th>fl2</th>\n",
       "      <th>fl3</th>\n",
       "      <th>fl4</th>\n",
       "      <th>fl5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>35.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>07/21/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>07/30/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>01/16/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>01/17/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>03/15/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   fl1   fl2   fl3   fl4   fl5\n",
       "0     01/01/2001  31.0  53.0  74.0  76.0  68.0\n",
       "1     01/02/2001  27.0  36.0  73.0  26.0  42.0\n",
       "2     01/03/2001  26.0  45.0  62.0  25.0  54.0\n",
       "3     01/04/2001  35.0  51.0  66.0  53.0  64.0\n",
       "4     01/05/2001  47.0  56.0  60.0  41.0  48.0\n",
       "...          ...   ...   ...   ...   ...   ...\n",
       "8030  07/21/2019   NaN  30.0  39.0  28.0  31.0\n",
       "8031  07/30/2019   NaN  34.0  46.0  53.0  31.0\n",
       "8032  01/16/2020   NaN  46.0  38.0  28.0  39.0\n",
       "8033  01/17/2020   NaN  40.0  41.0  39.0  41.0\n",
       "8034  03/15/2020   NaN  34.0  55.0  62.0  31.0\n",
       "\n",
       "[8035 rows x 6 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "florida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ea946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "11ebd014",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd1=nd_1.iloc[:,[0,1]]\n",
    "nd2=pd.merge(nd1,nd_2,how=\"outer\",on=\"Date\")\n",
    "nd2=nd2.iloc[:,[0,1,2]]\n",
    "n_dakota=pd.merge(nd2,nd_3,how=\"outer\",on=\"Date\")\n",
    "n_dakota=n_dakota.iloc[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "61ad6f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dakota.columns=['Date','nd1','nd2','nd3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c3fb5ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>nd1</th>\n",
       "      <th>nd2</th>\n",
       "      <th>nd3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>12/31/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>01/31/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>03/31/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>04/30/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>05/31/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   nd1   nd2   nd3\n",
       "0     01/01/2001  30.0  53.0  29.0\n",
       "1     01/02/2001  32.0  25.0  31.0\n",
       "2     01/03/2001  32.0  33.0  31.0\n",
       "3     01/04/2001  33.0  36.0  33.0\n",
       "4     01/05/2001  32.0  31.0  30.0\n",
       "...          ...   ...   ...   ...\n",
       "8030  12/31/2017   NaN   NaN   7.0\n",
       "8031  01/31/2018   NaN   NaN   4.0\n",
       "8032  03/31/2018   NaN   NaN   2.0\n",
       "8033  04/30/2018   NaN   NaN   4.0\n",
       "8034  05/31/2018   NaN   NaN   8.0\n",
       "\n",
       "[8035 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_dakota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8d919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "06d4ad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\571245152.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ny4=pd.merge(ny3,ny_4,how=\"outer\",on=\"Date\")\n"
     ]
    }
   ],
   "source": [
    "ny1=ny_1.iloc[:,[0,1]]\n",
    "ny2=pd.merge(ny1,ny_2,how=\"outer\",on=\"Date\")\n",
    "ny2=ny2.iloc[:,[0,1,2]]\n",
    "ny3=pd.merge(ny2,ny_3,how=\"outer\",on=\"Date\")\n",
    "ny3=ny3.iloc[:,[0,1,2,3]]\n",
    "ny4=pd.merge(ny3,ny_4,how=\"outer\",on=\"Date\")\n",
    "ny4=ny4.iloc[:,[0,1,2,3,4]]\n",
    "new_york=pd.merge(ny4,ny_5,how=\"outer\",on=\"Date\")\n",
    "new_york=new_york.iloc[:,[0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "917651b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_york.columns=['Date','ny1','ny2','ny3','ny4','ny5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "01f86fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ny1</th>\n",
       "      <th>ny2</th>\n",
       "      <th>ny3</th>\n",
       "      <th>ny4</th>\n",
       "      <th>ny5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>54.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>86.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>86.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>07/29/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>08/03/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>08/04/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>08/06/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>08/07/2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   ny1    ny2    ny3    ny4    ny5\n",
       "0     01/01/2001  42.0   37.0   38.0   38.0   30.0\n",
       "1     01/02/2001  54.0   39.0   45.0   30.0   18.0\n",
       "2     01/03/2001  70.0   31.0   58.0   44.0   15.0\n",
       "3     01/04/2001  86.0   35.0   82.0   87.0   72.0\n",
       "4     01/05/2001  86.0   23.0   74.0   48.0    3.0\n",
       "...          ...   ...    ...    ...    ...    ...\n",
       "8030  07/29/2001   NaN   50.0   39.0   38.0   44.0\n",
       "8031  08/03/2001   NaN   71.0   62.0   50.0   58.0\n",
       "8032  08/04/2001   NaN   97.0   70.0   44.0   31.0\n",
       "8033  08/06/2001   NaN  105.0  101.0   93.0  164.0\n",
       "8034  08/07/2001   NaN  156.0  192.0  213.0  202.0\n",
       "\n",
       "[8035 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_york"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d8cd3",
   "metadata": {},
   "source": [
    "Ohio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a8fd9d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\1532155328.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  ohio=pd.merge(oh3,oh_4,how=\"outer\",on=\"Date\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>oh1</th>\n",
       "      <th>oh2</th>\n",
       "      <th>oh3</th>\n",
       "      <th>oh4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>68.0</td>\n",
       "      <td>41</td>\n",
       "      <td>100.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>77.0</td>\n",
       "      <td>62</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>81.0</td>\n",
       "      <td>72</td>\n",
       "      <td>77.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67</td>\n",
       "      <td>77.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>59.0</td>\n",
       "      <td>68</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>12/16/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>34.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>12/18/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>12/19/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>45.0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>01/21/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>11/07/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   oh1  oh2    oh3  oh4\n",
       "0     01/01/2001  68.0   41  100.0   68\n",
       "1     01/02/2001  77.0   62   72.0   68\n",
       "2     01/03/2001  81.0   72   77.0   92\n",
       "3     01/04/2001  73.0   67   77.0   89\n",
       "4     01/05/2001  59.0   68   68.0   62\n",
       "...          ...   ...  ...    ...  ...\n",
       "8030  12/16/2016   NaN   45   34.0   38\n",
       "8031  12/18/2016   NaN   35   29.0   32\n",
       "8032  12/19/2016   NaN   45   45.0   61\n",
       "8033  01/21/2017   NaN   51   25.0   63\n",
       "8034  11/07/2019   NaN   36   51.0   43\n",
       "\n",
       "[8035 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oh1=oh_1.iloc[:,[0,1]]\n",
    "oh2=pd.merge(oh1,oh_2,how=\"outer\",on=\"Date\")\n",
    "oh2=oh2.iloc[:,[0,1,2]]\n",
    "oh3=pd.merge(oh2,oh_3,how=\"outer\",on=\"Date\")\n",
    "oh3=oh3.iloc[:,[0,1,2,3]]\n",
    "ohio=pd.merge(oh3,oh_4,how=\"outer\",on=\"Date\")\n",
    "ohio=ohio.iloc[:,[0,1,2,3,4]]\n",
    "\n",
    "ohio.columns=['Date','oh1','oh2','oh3','oh4']\n",
    "\n",
    "ohio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a83f75d",
   "metadata": {},
   "source": [
    "Oklahoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b672b83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ok1</th>\n",
       "      <th>ok2</th>\n",
       "      <th>ok3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>42.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>12/04/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>12/05/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>12/06/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>05/05/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>06/01/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   ok1   ok2   ok3\n",
       "0     01/01/2001  30.0  44.0  61.0\n",
       "1     01/02/2001  35.0  31.0   NaN\n",
       "2     01/03/2001  38.0  25.0   NaN\n",
       "3     01/04/2001  37.0  28.0   NaN\n",
       "4     01/05/2001  42.0  28.0   NaN\n",
       "...          ...   ...   ...   ...\n",
       "8030  12/04/2021   NaN  57.0  61.0\n",
       "8031  12/05/2021   NaN  53.0  47.0\n",
       "8032  12/06/2021   NaN  32.0  31.0\n",
       "8033  05/05/2022   NaN  32.0  31.0\n",
       "8034  06/01/2022   NaN  38.0  38.0\n",
       "\n",
       "[8035 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok1=ok_1.iloc[:,[0,1]]\n",
    "ok2=pd.merge(ok1,ok_2,how=\"outer\",on=\"Date\")\n",
    "ok2=ok2.iloc[:,[0,1,2]]\n",
    "oklahoma=pd.merge(ok2,ok_3,how=\"outer\",on=\"Date\")\n",
    "oklahoma=oklahoma.iloc[:,[0,1,2,3]]\n",
    "\n",
    "oklahoma.columns=['Date','ok1','ok2','ok3']\n",
    "\n",
    "oklahoma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f886c",
   "metadata": {},
   "source": [
    "Pennsylvania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "12925f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\1559039668.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  penn4=pd.merge(penn3,penn_4,how=\"outer\",on=\"Date\")\n",
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\1559039668.py:10: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  pennsylvania=pd.merge(penn5,penn_6,how=\"outer\",on=\"Date\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>penn1</th>\n",
       "      <th>penn2</th>\n",
       "      <th>penn3</th>\n",
       "      <th>penn4</th>\n",
       "      <th>penn5</th>\n",
       "      <th>penn6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>33</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>50</td>\n",
       "      <td>63</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>35</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>38</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>73</td>\n",
       "      <td>53</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>51</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>82</td>\n",
       "      <td>65</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>61</td>\n",
       "      <td>85.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>40</td>\n",
       "      <td>54.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>63</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>61</td>\n",
       "      <td>97.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>78</td>\n",
       "      <td>62</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>72</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>113</td>\n",
       "      <td>62</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>12/31/2022</td>\n",
       "      <td>88</td>\n",
       "      <td>96.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  penn1  penn2  penn3  penn4  penn5  penn6\n",
       "0     01/01/2001     33   25.0   38.0     50     63   37.0\n",
       "1     01/02/2001     35   25.0   38.0     41     39   68.0\n",
       "2     01/03/2001     38   54.0   57.0     73     53   65.0\n",
       "3     01/04/2001     51   63.0   67.0     82     65   69.0\n",
       "4     01/05/2001     61   85.0   44.0     95     56   29.0\n",
       "...          ...    ...    ...    ...    ...    ...    ...\n",
       "8030  12/27/2022     40   54.0   52.0     58     49   47.0\n",
       "8031  12/28/2022     63   62.0   76.0     73     61   56.0\n",
       "8032  12/29/2022     61   97.0   93.0     78     62   77.0\n",
       "8033  12/30/2022     72  127.0  118.0    113     62   79.0\n",
       "8034  12/31/2022     88   96.0  105.0     74     61   45.0\n",
       "\n",
       "[8035 rows x 7 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penn1=penn_1.iloc[:,[0,1]]\n",
    "penn2=pd.merge(penn1,penn_2,how=\"outer\",on=\"Date\")\n",
    "penn2=penn2.iloc[:,[0,1,2]]\n",
    "penn3=pd.merge(penn2,penn_3,how=\"outer\",on=\"Date\")\n",
    "penn3=penn3.iloc[:,[0,1,2,3]]\n",
    "penn4=pd.merge(penn3,penn_4,how=\"outer\",on=\"Date\")\n",
    "penn4=penn4.iloc[:,[0,1,2,3,4]]\n",
    "penn5=pd.merge(penn4,penn_5,how=\"outer\",on=\"Date\")\n",
    "penn5=penn5.iloc[:,[0,1,2,3,4,5]]\n",
    "pennsylvania=pd.merge(penn5,penn_6,how=\"outer\",on=\"Date\")\n",
    "pennsylvania=pennsylvania.iloc[:,[0,1,2,3,4,5,6]]\n",
    "\n",
    "pennsylvania.columns=['Date','penn1','penn2','penn3','penn4','penn5','penn6']\n",
    "\n",
    "pennsylvania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f102f2",
   "metadata": {},
   "source": [
    "Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "21d5e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\2777079985.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  tx4=pd.merge(tx3,tx_4,how=\"outer\",on=\"Date\")\n",
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\2777079985.py:10: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  texas=pd.merge(tx5,tx_6,how=\"outer\",on=\"Date\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>tx1</th>\n",
       "      <th>tx2</th>\n",
       "      <th>tx3</th>\n",
       "      <th>tx4</th>\n",
       "      <th>tx5</th>\n",
       "      <th>tx6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>56</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>61</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>64</td>\n",
       "      <td>57.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>37.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>51</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>08/28/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>08/29/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>08/30/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>08/31/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>08/25/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>49</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   tx1   tx2  tx3   tx4   tx5   tx6\n",
       "0     01/01/2001  44.0  53.0   56  40.0  53.0  23.0\n",
       "1     01/02/2001  24.0  19.0   61  26.0  24.0  25.0\n",
       "2     01/03/2001  22.0  19.0   81  36.0  29.0  29.0\n",
       "3     01/04/2001  59.0  36.0   64  57.0  39.0  29.0\n",
       "4     01/05/2001  37.0  23.0   51  33.0  34.0  29.0\n",
       "...          ...   ...   ...  ...   ...   ...   ...\n",
       "8030  08/28/2017   NaN  33.0   50   NaN   NaN  35.0\n",
       "8031  08/29/2017   NaN  48.0   52   NaN   NaN  44.0\n",
       "8032  08/30/2017   NaN  48.0   51   NaN   NaN  45.0\n",
       "8033  08/31/2017   NaN  41.0   52   NaN  43.0  46.0\n",
       "8034  08/25/2020   NaN  47.0   49   9.0  45.0   NaN\n",
       "\n",
       "[8035 rows x 7 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx1=tx_1.iloc[:,[0,1]]\n",
    "tx2=pd.merge(tx1,tx_2,how=\"outer\",on=\"Date\")\n",
    "tx2=tx2.iloc[:,[0,1,2]]\n",
    "tx3=pd.merge(tx2,tx_3,how=\"outer\",on=\"Date\")\n",
    "tx3=tx3.iloc[:,[0,1,2,3]]\n",
    "tx4=pd.merge(tx3,tx_4,how=\"outer\",on=\"Date\")\n",
    "tx4=tx4.iloc[:,[0,1,2,3,4]]\n",
    "tx5=pd.merge(tx4,tx_5,how=\"outer\",on=\"Date\")\n",
    "tx5=tx5.iloc[:,[0,1,2,3,4,5]]\n",
    "texas=pd.merge(tx5,tx_6,how=\"outer\",on=\"Date\")\n",
    "texas=texas.iloc[:,[0,1,2,3,4,5,6]]\n",
    "\n",
    "texas.columns=['Date','tx1','tx2','tx3','tx4','tx5','tx6']\n",
    "\n",
    "texas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23624ecb",
   "metadata": {},
   "source": [
    "West Virginia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8744660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\3124446366.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  w_virginia=pd.merge(wv3,wv_4,how=\"outer\",on=\"Date\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>wv1</th>\n",
       "      <th>wv2</th>\n",
       "      <th>wv3</th>\n",
       "      <th>wv4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>55.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>01/13/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>01/14/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>04/23/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>11/17/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>11/18/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   wv1   wv2   wv3   wv4\n",
       "0     01/01/2001  55.0  67.0  34.0  77.0\n",
       "1     01/02/2001  12.0   NaN  28.0   NaN\n",
       "2     01/03/2001  15.0   NaN  31.0   NaN\n",
       "3     01/04/2001  59.0  57.0  39.0  56.0\n",
       "4     01/05/2001  14.0   NaN  26.0   NaN\n",
       "...          ...   ...   ...   ...   ...\n",
       "8030  01/13/2019   NaN   NaN  31.0   NaN\n",
       "8031  01/14/2019   NaN   NaN  23.0   NaN\n",
       "8032  04/23/2019   NaN   NaN  48.0  43.0\n",
       "8033  11/17/2022   NaN   NaN  27.0   NaN\n",
       "8034  11/18/2022   NaN   NaN  28.0   NaN\n",
       "\n",
       "[8035 rows x 5 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv1=wv_1.iloc[:,[0,1]]\n",
    "wv2=pd.merge(wv1,wv_2,how=\"outer\",on=\"Date\")\n",
    "wv2=wv2.iloc[:,[0,1,2]]\n",
    "wv3=pd.merge(wv2,wv_3,how=\"outer\",on=\"Date\")\n",
    "wv3=wv3.iloc[:,[0,1,2,3]]\n",
    "w_virginia=pd.merge(wv3,wv_4,how=\"outer\",on=\"Date\")\n",
    "w_virginia=w_virginia.iloc[:,[0,1,2,3,4]]\n",
    "\n",
    "w_virginia.columns=['Date','wv1','wv2','wv3','wv4']\n",
    "\n",
    "w_virginia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64b5a0",
   "metadata": {},
   "source": [
    "Wyoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b5a1e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyx\\AppData\\Local\\Temp\\ipykernel_16988\\1829721964.py:6: FutureWarning: Passing 'suffixes' which cause duplicate columns {' AQI Value_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  wyoming=pd.merge(wy3,wy_4,how=\"outer\",on=\"Date\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>wy1</th>\n",
       "      <th>wy2</th>\n",
       "      <th>wy3</th>\n",
       "      <th>wy4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2001</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2001</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2001</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2001</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2001</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8030</th>\n",
       "      <td>05/19/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>05/20/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>05/21/2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>12/19/2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>11/17/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   wy1   wy2   wy3   wy4\n",
       "0     01/01/2001  61.0   9.0  45.0  39.0\n",
       "1     01/02/2001  45.0  13.0  44.0  42.0\n",
       "2     01/03/2001  44.0  35.0  44.0  42.0\n",
       "3     01/04/2001  47.0  42.0  44.0  44.0\n",
       "4     01/05/2001  45.0  36.0  42.0  43.0\n",
       "...          ...   ...   ...   ...   ...\n",
       "8030  05/19/2007   NaN  24.0  74.0  74.0\n",
       "8031  05/20/2007   NaN  28.0  77.0  49.0\n",
       "8032  05/21/2007   NaN  19.0  46.0  47.0\n",
       "8033  12/19/2012   NaN  12.0  39.0  37.0\n",
       "8034  11/17/2013   NaN  14.0  41.0  39.0\n",
       "\n",
       "[8035 rows x 5 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wy1=wy_1.iloc[:,[0,1]]\n",
    "wy2=pd.merge(wy1,wy_2,how=\"outer\",on=\"Date\")\n",
    "wy2=wy2.iloc[:,[0,1,2]]\n",
    "wy3=pd.merge(wy2,wy_3,how=\"outer\",on=\"Date\")\n",
    "wy3=wy3.iloc[:,[0,1,2,3]]\n",
    "wyoming=pd.merge(wy3,wy_4,how=\"outer\",on=\"Date\")\n",
    "wyoming=wyoming.iloc[:,[0,1,2,3,4]]\n",
    "\n",
    "wyoming.columns=['Date','wy1','wy2','wy3','wy4']\n",
    "\n",
    "wyoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "876df8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "california.to_csv('california_raw.csv',encoding='utf-8', index=False)\n",
    "florida.to_csv('florida_raw.csv',encoding='utf-8', index=False)\n",
    "n_dakota.to_csv('n_dakota_raw.csv',encoding='utf-8', index=False)\n",
    "new_york.to_csv('new_york_raw.csv',encoding='utf-8', index=False)\n",
    "ohio.to_csv('ohio_raw.csv',encoding='utf-8', index=False)\n",
    "oklahoma.to_csv('oklahoma_raw.csv',encoding='utf-8', index=False)\n",
    "pennsylvania.to_csv('pennsylvania_raw.csv',encoding='utf-8', index=False)\n",
    "texas.to_csv('texas_raw.csv',encoding='utf-8', index=False)\n",
    "w_virginia.to_csv('w_virginia_raw.csv',encoding='utf-8', index=False)\n",
    "wyoming.to_csv('wyoming_raw.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fillna\n",
    "\n",
    "def fill_nans_row_avg_for_state(state_csv_file_name):\n",
    "    state_daily_aqi_df = pd.read_csv(state_csv_file_name)\n",
    "  \n",
    "  # convert all columns except the first to floats\n",
    "    state_daily_aqi_df.iloc[:, 1:] = state_daily_aqi_df.iloc[:, 1:].astype(float)\n",
    "\n",
    "  # fill NaNs in each row with the row average (excluding the first column)\n",
    "    row_means = state_daily_aqi_df.iloc[:, 1:].mean(axis=1)\n",
    "    state_daily_aqi_df.iloc[:, 1:] = state_daily_aqi_df.iloc[:, 1:].apply(lambda x: x.fillna(row_means))\n",
    " \n",
    "    row_means_after = pd.DataFrame(state_daily_aqi_df.iloc[:, 1:].mean(axis=1))\n",
    "    state_daily_aqi_df[\"average\"]=row_means_after\n",
    "    \n",
    "    return state_daily_aqi_df\n",
    "\n",
    "california_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/california_raw.csv\")\n",
    "texas_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/texas_raw.csv\")\n",
    "n_dakota_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/n_dakota_raw.csv\")\n",
    "wyoming_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/wyoming_raw.csv\")\n",
    "pennsylvania_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/pennsylvania_raw.csv\")\n",
    "w_virginia_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/w_virginia_raw.csv\")\n",
    "oklahoma_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/oklahoma_raw.csv\")\n",
    "new_york_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/new_york_raw.csv\")\n",
    "ohio_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/ohio_raw.csv\")\n",
    "florida_filled = fill_nans_row_avg_for_state(\"C:/Users/cyx/Desktop/merged data(to be filled)/raw data by state/florida_raw.csv\")\n",
    "\n",
    "california_av=california_filled[['Date','average']]\n",
    "texas_av=texas_filled[['Date','average']]\n",
    "wyoming_av=wyoming_filled[['Date','average']]\n",
    "oklahoma_av=oklahoma_filled[['Date','average']]\n",
    "ohio_av=ohio_filled[['Date','average']]\n",
    "w_virginia_av=w_virginia_filled[['Date','average']]\n",
    "florida_av=florida_filled[['Date','average']]\n",
    "new_york_av=new_york_filled[['Date','average']]\n",
    "n_dakota_av=n_dakota_filled[['Date','average']]\n",
    "pennsylvania_av=pennsylvania_filled[['Date','average']]\n",
    "\n",
    "Merge all states by date\n",
    "\n",
    "df2=pd.merge(california_av,texas_av,how=\"outer\",on=\"Date\")\n",
    "df3=pd.merge(df2,n_dakota_av,how=\"outer\",on=\"Date\")\n",
    "df4=pd.merge(df3,wyoming_av,how=\"outer\",on=\"Date\")\n",
    "df5=pd.merge(df4,pennsylvania_av,how=\"outer\",on=\"Date\")\n",
    "df6=pd.merge(df5,w_virginia_av,how=\"outer\",on=\"Date\")\n",
    "df7=pd.merge(df6,oklahoma_av,how=\"outer\",on=\"Date\")\n",
    "df8=pd.merge(df7,florida_av,how=\"outer\",on=\"Date\")\n",
    "df9=pd.merge(df8,new_york_av,how=\"outer\",on=\"Date\")\n",
    "df10=pd.merge(df9,ohio_av,how=\"outer\",on=\"Date\")\n",
    "\n",
    "df10.columns=['Date','california','texas','n_dakota','wyoming','pennsylvania','w_virginia','oklahoma','florida','new_york','ohio']\n",
    "\n",
    "df10\n",
    "\n",
    "df10.dtypes\n",
    "#type of date is object\n",
    "\n",
    "df10[\"date2\"]=pd.to_datetime(df10['Date'],format='%m/%d/%Y')\n",
    "\n",
    "california=df10.california\n",
    "texas=df10.texas\n",
    "n_dakota=df10.n_dakota\n",
    "wyoming=df10.wyoming\n",
    "pennsylvania=df10.pennsylvania\n",
    "w_virginia=df10.w_virginia\n",
    "oklahoma=df10.oklahoma\n",
    "florida=df10.florida\n",
    "new_york=df10.new_york\n",
    "ohio=df10.ohio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "california.index=df10['date2']\n",
    "texas.index=df10['date2']\n",
    "n_dakota.index=df10['date2']\n",
    "wyoming.index=df10['date2']\n",
    "pennsylvania.index=df10['date2']\n",
    "w_virginia.index=df10['date2']\n",
    "oklahoma.index=df10['date2']\n",
    "florida.index=df10['date2']\n",
    "new_york.index=df10['date2']\n",
    "ohio.index=df10['date2']\n",
    "\n",
    "california_month=california.resample('m').mean()\n",
    "texas_month=texas.resample('m').mean()\n",
    "n_dakota_month=n_dakota.resample('m').mean()\n",
    "wyoming_month=wyoming.resample('m').mean()\n",
    "pennsylvania_month=pennsylvania.resample('m').mean()\n",
    "w_virginia_month=w_virginia.resample('m').mean()\n",
    "oklahoma_month=oklahoma.resample('m').mean()\n",
    "florida_month=florida.resample('m').mean()\n",
    "new_york_month=new_york.resample('m').mean()\n",
    "ohio_month=ohio.resample('m').mean()\n",
    "\n",
    "d2=pd.merge(california_month,texas_month,how=\"outer\",on='date2')\n",
    "d3=pd.merge(d2,n_dakota_month,how=\"outer\",on=\"date2\")\n",
    "d4=pd.merge(d3,wyoming_month,how=\"outer\",on=\"date2\")\n",
    "d5=pd.merge(d4,pennsylvania_month,how=\"outer\",on=\"date2\")\n",
    "d6=pd.merge(d5,w_virginia_month,how=\"outer\",on=\"date2\")\n",
    "d7=pd.merge(d6,oklahoma_month,how=\"outer\",on=\"date2\")\n",
    "d8=pd.merge(d7,florida_month,how=\"outer\",on=\"date2\")\n",
    "d9=pd.merge(d8,new_york_month,how=\"outer\",on=\"date2\")\n",
    "d10=pd.merge(d9,ohio_month,how=\"outer\",on=\"date2\")\n",
    "\n",
    "d10\n",
    "\n",
    "d10.to_csv('air_monthly.csv',encoding='utf-8', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
